{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db8421b-c0bd-4c54-93bc-6a7ca33ca75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Valentin.CHABAUX\\miniconda3\\envs\\text\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position interpolate from 16x16 to 26x26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Valentin.CHABAUX\\miniconda3\\envs\\text\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "C:\\Users\\Valentin.CHABAUX\\miniconda3\\envs\\text\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "try:import gradio as gr\n",
    "except:\n",
    "  %pip install gradio\n",
    "  import gradio as gr\n",
    "\n",
    "try:import xmltodict\n",
    "except:\n",
    "  %pip install xmltodict\n",
    "  import xmltodict\n",
    "\n",
    "try:from lavis.models import load_model_and_preprocess\n",
    "except:\n",
    "  %pip install salesforce-lavis\n",
    "  from lavis.models import load_model_and_preprocess\n",
    "\n",
    "try:from transformers import MarianMTModel, MarianTokenizer\n",
    "except:\n",
    "  %pip install transformers\n",
    "  from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "try:from sentence_transformers import SentenceTransformer, util\n",
    "except:\n",
    "  %pip install sentence-transformers\n",
    "  from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import csv\n",
    "from math import dist\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "from urllib.error import HTTPError, URLError\n",
    "import requests\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "DIR_BASE = \"IMG_CORPUS\"\n",
    "DIR_INDEX = \"IMG_INDEXS\"\n",
    "\n",
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_feature_extractor\", model_type=\"coco\", device=\"cuda\")\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "marian = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1254b03d-98a1-4517-ba78-af7ff6048533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nombre_pages(ark):\n",
    "  # In :  identifiant ark\n",
    "  # Out : nombre de pages (int)\n",
    "  PAGINATION_BASEURL = 'https://gallica.bnf.fr/services/Pagination?ark='\n",
    "  url = \"\".join([PAGINATION_BASEURL, ark])\n",
    "  s = requests.get(url, stream=True)\n",
    "  paginationdic = xmltodict.parse(s.text)\n",
    "  nb_pages = int(paginationdic[\"livre\"][\"structure\"][\"nbVueImages\"])\n",
    "  return nb_pages\n",
    "    \n",
    "def rect_distance(rect1, rect2):\n",
    "    x1, y1, x1b, y1b = rect1\n",
    "    x2, y2, x2b, y2b = rect2\n",
    "    \n",
    "    # Coordonnées des milieux des côtés\n",
    "    milieu_haut_rect2 = ((x2 + x2b) / 2, y2)\n",
    "    milieu_bas_rect1 = ((x1 + x1b) / 2, y1b)\n",
    "    \n",
    "    # Calcul de la distance entre les milieux\n",
    "    distance = dist(milieu_haut_rect2, milieu_bas_rect1)\n",
    "    \n",
    "    return distance\n",
    "    \n",
    "def translate_legend(row):\n",
    "    if row[\"legend\"] is not np.nan and row[\"legend\"] is not None and row[\"legend\"].strip() != \"\":\n",
    "        inputs = tokenizer.encode(row[\"legend\"], return_tensors=\"pt\")\n",
    "        outputs = marian.generate(inputs, num_beams=4, max_length=50, early_stopping=True)\n",
    "        translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(row[\"legend\"], translated_text)\n",
    "        return translated_text\n",
    "    else:\n",
    "        print(row[\"legend\"], \"\")\n",
    "        return \"\"       \n",
    "\n",
    "def get_embedding(row):\n",
    "    img_path = row[\"img_path\"]\n",
    "    txt = row[\"en_legend\"] if row[\"en_legend\"] is not np.nan else \"\"\n",
    "    \n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image_processed = vis_processors[\"eval\"](image).unsqueeze(0).to(\"cuda\")\n",
    "    text_input = txt_processors[\"eval\"](txt)\n",
    "    sample = {\"image\": image_processed, \"text_input\": text_input}\n",
    "\n",
    "    # English embedding\n",
    "    text_emb = model.extract_features(sample, mode=\"text\").text_embeds_proj[:,0,:] # size (1, 768)\n",
    "    text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Image embedding\n",
    "    image_emb = model.extract_features(sample, mode=\"image\").image_embeds_proj[:,0,:] # size (1, 768)\n",
    "    image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # French embedding\n",
    "    txt_fr = row[\"legend\"] if row[\"legend\"] is not np.nan else \"\"\n",
    "    text_fr_input = txt_processors[\"eval\"](txt)\n",
    "    sample_french = {\"image\": image_processed, \"text_input\": text_fr_input}\n",
    "    text_fr_emb = model.extract_features(sample_french, mode=\"text\").text_embeds_proj[:,0,:] # size (1, 768)\n",
    "    text_fr_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    print(img_path, txt)\n",
    "    \n",
    "    return [text_emb, text_fr_emb, image_emb, torch.stack([text_emb,image_emb]).mean(dim=0), torch.stack([text_fr_emb,image_emb]).mean(dim=0)]\n",
    "\n",
    "base = None\n",
    "def load_csv(corpus_select):\n",
    "    global DIR_INDEX\n",
    "    global base\n",
    "    print(corpus_select)\n",
    "    base = pd.read_csv(DIR_INDEX+\"/\"+corpus_select)\n",
    "    base['embedding'] = base['embedding'].apply(lambda x: eval(x)) \n",
    "\n",
    "def search_ark_fn(search_ark, coll_name):\n",
    "    arks=search_ark.split(\",\")\n",
    "    global DIR_BASE\n",
    "    global DIR_INDEX\n",
    "    try:\n",
    "        os.makedirs(DIR_BASE)        \n",
    "    except FileExistsError:pass\n",
    "    try:\n",
    "        os.makedirs(DIR_BASE+\"/\"+coll_name)        \n",
    "    except:\n",
    "        return \"Erreur : ce nom de collection exite déjà ou n'est pas valide !\"\n",
    "    try:\n",
    "        os.makedirs(DIR_INDEX)        \n",
    "    except FileExistsError:pass\n",
    "\n",
    "    base_img = []\n",
    "    for ark in arks:\n",
    "        links = {}\n",
    "        pages = nombre_pages(ark)\n",
    "        print(\"\\nARK :\", ark)\n",
    "        for page in range(1, pages+1) : \n",
    "            images = []\n",
    "            texts = []\n",
    "            alto_url = 'https://gallica.bnf.fr/RequestDigitalElement?O={}&E=ALTO&Deb={}'.format(ark, page)\n",
    "            s = requests.get(alto_url, stream=True)\n",
    "            try:\n",
    "                altodic = xmltodict.parse(s.text)\n",
    "            except : \n",
    "                print(ark, \"non océrisé. Skiped\")\n",
    "                break\n",
    "            print(\"==========\", \"Page\", page,\"==========\")\n",
    "            cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"TextBlock\", [])\n",
    "            if not isinstance(cbs, list): cbs = [cbs]\n",
    "            for cb in cbs:\n",
    "                #print(\"TEXT:\", \"x:\",int(cb[\"@HPOS\"]),\"y:\",int(cb[\"@VPOS\"]),\"xb:\",int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]),\"yb:\",int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"]))\n",
    "                content = []\n",
    "                textLines = cb.get(\"TextLine\",[])\n",
    "                if not isinstance(textLines, list): textLines = [textLines]\n",
    "                for textLine in textLines:\n",
    "                    strings = textLine.get(\"String\",[])\n",
    "                    if not isinstance(strings, list): strings = [strings]\n",
    "                    content.extend(string.get(\"@CONTENT\") for string in strings)\n",
    "                texts.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), \" \".join(content)))        \n",
    "                #print(texts)\n",
    "            cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"Illustration\", [])\n",
    "            if not isinstance(cbs, list): cbs = [cbs]\n",
    "            for cb in cbs:\n",
    "                #print(\"IMAGE:\", \"x:\",int(cb[\"@HPOS\"]),\"y:\",int(cb[\"@VPOS\"]),\"xb:\",int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]),\"yb:\",int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"]))   \n",
    "        \n",
    "                images.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), cb))\n",
    "            cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"ComposedBlock\", [])\n",
    "            if not isinstance(cbs, list): cbs = [cbs]\n",
    "            for cb in cbs:\n",
    "                illustration = cb.get(\"Illustration\", [])\n",
    "                if not isinstance(illustration, list): illustration = [illustration]\n",
    "                textBlocks = cb.get(\"TextBlock\", [])\n",
    "                if not isinstance(textBlocks, list): textBlocks = [textBlocks]\n",
    "                for cb in textBlocks:\n",
    "                    #print(\"TEXT[CB]:\", \"x:\",int(cb[\"@HPOS\"]),\"y:\",int(cb[\"@VPOS\"]),\"xb:\",int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]),\"yb:\",int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"]))\n",
    "                    content = []\n",
    "                    textLines = cb.get(\"TextLine\",[])\n",
    "                    if not isinstance(textLines, list): textLines = [textLines]\n",
    "                    for textLine in textLines:\n",
    "                        strings = textLine.get(\"String\",[])\n",
    "                        if not isinstance(strings, list): strings = [strings]\n",
    "                        content.extend(string.get(\"@CONTENT\") for string in strings)\n",
    "                    texts.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), \" \".join(content)))        \n",
    "                    #print(texts)\n",
    "                for cb in illustration:\n",
    "                    #print(\"IMAGE[CB]:\", \"x:\",int(cb[\"@HPOS\"]),\"y:\",int(cb[\"@VPOS\"]),\"xb:\",int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]),\"yb:\",int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"]))\n",
    "                    images.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])),cb))\n",
    "            #print(images)\n",
    "            #print(texts)\n",
    "            for i,img in enumerate(images) :\n",
    "                url = \"https://gallica.bnf.fr/iiif/ark:/12148/{}/f{}/{},{},{},{}/{}/0/native.jpg\".format(ark,page,img[1][\"@HPOS\"],img[1][\"@VPOS\"],img[1][\"@WIDTH\"],img[1][\"@HEIGHT\"],\"full\")\n",
    "                print(\"Image\", i)\n",
    "                nomfichier = ark+\"_\"+str(page)+\"_\"+img[1][\"@ID\"]+\".jpg\"\n",
    "                cheminout = DIR_BASE+\"/\"+coll_name+\"/\"+nomfichier                \n",
    "\n",
    "                while True:\n",
    "                    try :\n",
    "                        urllib.request.urlretrieve(url, cheminout)\n",
    "                    except (HTTPError, URLError) as erreur:\n",
    "                        print(str(erreur.reason))\n",
    "                        print(\"wait 10 seconds\")\n",
    "                        time.sleep(10)\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    #imagePIL = Image.open(requests.get(url, stream=True).raw)\n",
    "                    #display(imagePIL)\n",
    "                    txt_rank = []\n",
    "                    legend = []\n",
    "                    for txt in texts:\n",
    "                        distance = rect_distance(img[0], txt[0])\n",
    "                        if distance <80 : legend.append(txt[1])\n",
    "                        txt_rank.append((distance, txt[1]))\n",
    "                    txt_rank.sort(key= lambda x : x[0])\n",
    "                    txt_legned = \" \".join(legend)\n",
    "                    print(\"Description :\",txt_legned)\n",
    "                    #for rank in txt_rank:print(rank)\n",
    "                    base_img.append((cheminout, txt_legned))\n",
    "                except:\n",
    "                    pass\n",
    "                        \n",
    "    index_df = pd.DataFrame(base_img, columns=[\"img_path\", \"legend\"])\n",
    "    \n",
    "    legends = index_df[\"legend\"].tolist()\n",
    "    translated = marian.generate(**tokenizer(legends, return_tensors=\"pt\", padding=True))\n",
    "    en_legends = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "    index_df[\"en_legend\"] = np.array(en_legends)\n",
    "    index_df[\"en_legend\"][(index_df[\"legend\"].isna()) | (index_df[\"legend\"].str.strip() == \"\") | (index_df[\"legend\"] is None)] = \"\"    \n",
    "    #index_df[\"en_legend\"] = index_df.apply(translate_legend, axis = 1)\n",
    "    index_df[\"embedding\"] = index_df.apply(get_embedding, axis = 1)\n",
    "    index_df.to_csv(DIR_INDEX+\"/\"+coll_name+\".csv\", index=False, encoding=\"utf-8\")  \n",
    "\n",
    "def update_corpus():    \n",
    "    corpus = []    \n",
    "    for csv_file in os.listdir(DIR_INDEX):\n",
    "        if csv_file.lower().endswith('.csv'):\n",
    "            corpus.append(csv_file)\n",
    "    return gr.update(choices=corpus)\n",
    "\n",
    "    \n",
    "def deactivate():\n",
    "    return gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False)\n",
    "\n",
    "def activate():\n",
    "    return gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True)\n",
    "\n",
    "def search(input_search_txt, input_search_type, img_count):\n",
    "    global base\n",
    "    def sim_calc(row):\n",
    "        text_sim = -1 if row[\"en_legend\"] is np.nan or row[\"en_legend\"] == \"\" else util.cos_sim(row[\"embedding\"][0], input_search_embedding).cpu().numpy()[0]\n",
    "        text_fr_sim = -1 if row[\"legend\"] is np.nan or row[\"legend\"] == \"\" else util.cos_sim(row[\"embedding\"][1], input_search_embedding).cpu().numpy()[0]\n",
    "        image_sim = util.cos_sim(row[\"embedding\"][2], input_search_embedding)\n",
    "        mean_sim = util.cos_sim(row[\"embedding\"][3], input_search_embedding)\n",
    "        mean_fr_sim = util.cos_sim(row[\"embedding\"][4], input_search_embedding)\n",
    "        return [text_sim, text_fr_sim, image_sim.cpu().numpy()[0], mean_sim.cpu().numpy()[0], mean_fr_sim.cpu().numpy()[0]]\n",
    "    \n",
    "    def get_text_sim(row):\n",
    "        return row[\"sim\"][0]\n",
    "    \n",
    "    def get_text_fr_sim(row):\n",
    "        return row[\"sim\"][1]\n",
    "    \n",
    "    def get_image_sim(row):\n",
    "        return row[\"sim\"][2]\n",
    "    \n",
    "    def get_mean_sim(row):\n",
    "        return row[\"sim\"][3]\n",
    "    \n",
    "    def get_mean_fr_sim(row):\n",
    "        return row[\"sim\"][4]\n",
    "    \n",
    "    print(input_search_txt)\n",
    "    images = []\n",
    "    inputs = tokenizer.encode(input_search_txt, return_tensors=\"pt\")\n",
    "    outputs = marian.generate(inputs, num_beams=4, max_length=50, early_stopping=True)\n",
    "    input_search_tk = tokenizer.decode(outputs[0], skip_special_tokens=True)   \n",
    "\n",
    "        \n",
    "    input_search = txt_processors[\"eval\"](input_search_tk)\n",
    "    input_search_sample = {\"image\": None, \"text_input\": [input_search]}\n",
    "    input_search_embedding = model.extract_features(input_search_sample, mode=\"text\").text_embeds_proj[:,0,:] # size (1, 768)\n",
    "    input_search_embedding /= input_search_embedding.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    base['sim'] = base.apply(sim_calc, axis = 1)\n",
    "    \n",
    "    base[\"text_sim\"] = base.apply(get_text_sim, axis = 1)\n",
    "    text_sim_moy = base[base['text_sim'] != -1]['text_sim'].mean()\n",
    "    base['text_sim'][base['text_sim'] == -1] = text_sim_moy\n",
    "    \n",
    "    base[\"text_fr_sim\"] = base.apply(get_text_fr_sim, axis = 1)\n",
    "    text_fr_sim_moy = base[base['text_fr_sim'] != -1]['text_fr_sim'].mean()\n",
    "    base['text_fr_sim'][base['text_fr_sim'] == -1] = text_fr_sim_moy\n",
    "    \n",
    "    base[\"image_sim\"] = base.apply(get_image_sim, axis = 1)\n",
    "    base[\"mean_sim\"] = base.apply(get_mean_sim, axis = 1)\n",
    "    base[\"mean_fr_sim\"] = base.apply(get_mean_fr_sim, axis = 1)\n",
    "    base[\"total_mean\"]= (base[\"text_sim\"] +base[\"image_sim\"]+base[\"mean_sim\"])/3\n",
    "    if input_search_type == \"Texte & Image\":\n",
    "        filter = \"total_mean\"\n",
    "    elif input_search_type == \"Image\":\n",
    "        filter = \"image_sim\"\n",
    "    else:\n",
    "        filter = \"text_sim\"\n",
    "        \n",
    "    for index, row in base.sort_values(filter, ascending=False).head(img_count).iterrows():\n",
    "        image = Image.open(row[\"img_path\"]).convert(\"RGB\")\n",
    "        images.append((image, str(row[\"legend\"])))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eeff667-abbf-4bc2-a730-9270c8a934a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Valentin.CHABAUX\\miniconda3\\envs\\text\\Lib\\site-packages\\gradio\\components\\dropdown.py:179: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: 0 or set allow_custom_value=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manuels_histoire.csv\n",
      "Château\n",
      "cheval\n",
      "cheval\n",
      "chevaux\n",
      "cartes geographie\n",
      "Moustache\n",
      "outils artisanat\n",
      "Charlemagne\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Recherche\"):\n",
    "        with gr.Row():\n",
    "            corpus_select = gr.Dropdown([], label=\"Corpus\", info=\"Choisissez un corpus\", value=0)\n",
    "            update_btn = gr.Button(\"Rafraîchir la liste des corpus\")\n",
    "        with gr.Row():\n",
    "            search_type = gr.Dropdown([\"Texte & Image\", \"Image\", \"Texte\"], label=\"Type de recherche\", info=\"Choisissez un type de recherche\", value=0, interactive = False)\n",
    "            search_txt = gr.Textbox(label=\"Recherche\", info=\"Texte pour la recherche d'images\", interactive = False)\n",
    "        with gr.Row():\n",
    "            img_count = gr.Slider(1, 25, value=5, label=\"Nombre d'images\", info=\"Choisissez le nombre d'images à rechercher\", step=1, interactive = False)\n",
    "        with gr.Row():\n",
    "            search_btn = gr.Button(\"Rechercher des images\", interactive = False)\n",
    "        with gr.Row():\n",
    "            gallery = gr.Gallery(label=\"Generated images\", show_label=False, elem_id=\"gallery\", columns=[3], rows=[1], object_fit=\"fill\", height=\"auto\", interactive = False)\n",
    "       \n",
    "    with gr.Tab(\"Collecte\"):\n",
    "        coll_name = gr.Textbox(label=\"Nom de collection\", info=\"Entrez le nom de votre collection\", interactive = True)\n",
    "        search_ark = gr.Textbox(label=\"Arks\", info=\"Identifiants Arks à collecter\", interactive = True)\n",
    "        search_ark_btn = gr.Button(\"Lancer la collecte et les traitements\", interactive = True)\n",
    "        output_ark = gr.Textbox(label=\"Console\", info=\"Logs de la collecte\", interactive = False)\n",
    "        \n",
    "    search_btn.click(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn]).then(search, inputs=[search_txt,search_type, img_count], outputs=[gallery]).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn])\n",
    "    update_btn.click(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn]).then(update_corpus, outputs=[corpus_select]).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn])\n",
    "    search_ark_btn.click(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn]).then(search_ark_fn, inputs=[search_ark, coll_name], outputs=[output_ark]).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn])\n",
    "    corpus_select.change(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn]).then(load_csv, inputs=[corpus_select], show_progress=True).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, coll_name, search_ark, search_ark_btn])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8a28b-37b9-45c3-90d8-879dcc3d79a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
